{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "\n",
    "`dlt` is an open-source library that you can add to your Python scripts to load data from various and often messy data sources into well-structured, live datasets.\n",
    "\n",
    "How it works?\n",
    "\n",
    "`dlt` extracts data from a source, inspects its structure to generate a schema, organizes, normalizes and verifies the data, and loads the data into a destination, such as a database.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1abaa769cf924bf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![img](images/dlt-high-level.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9d91f5b4f22a285"
  },
  {
   "cell_type": "markdown",
   "id": "9240f2fb-1909-4ef4-b80e-5b76c1aa77aa",
   "metadata": {},
   "source": [
    "Below, we give you a preview of how you can get data from APIs, files, Python objects or pandas dataframes and move it into a local or remote database, data lake or a vector data store. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0bcb3-f6f3-40b4-a8f5-9d1c0bd7084a",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Official releases of dlt can be installed from [PyPI](https://pypi.org/project/dlt/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8088e93-0f5d-4975-a670-29e1cc58607a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:08:35.171038620Z",
     "start_time": "2023-09-04T09:08:32.710649363Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25f96c-444c-4b56-b1af-0e1075145181",
   "metadata": {},
   "source": [
    "Command above just installs library core, in example below we use `duckdb` as a [destination](https://dlthub.com/docs/dlt-ecosystem/destinations), so let's add it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e4d5059c-d0e6-49a1-9e41-998d14022baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:08:58.838489545Z",
     "start_time": "2023-09-04T09:08:55.336391284Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q \"dlt[duckdb]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34b265-3ae7-443c-985c-28740068c9e6",
   "metadata": {},
   "source": [
    "> Use clean virtual environment for your experiments! Here are [detailed instructions](https://dlthub.com/docs/reference/installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143f5c7-e234-4dbc-b62c-c974bfc1c815",
   "metadata": {},
   "source": [
    "## Quick start\n",
    "\n",
    "Let's load a list of Python objects (dicts) into `duckdb` database and inspect the created dataset.\n",
    "\n",
    "> We gonna use `full_refresh` for our test examples. If you create a new pipeline script you will be experimenting a lot. If you want that each time the pipeline resets its state and loads data to a new dataset, set the full_refresh argument of the dlt.pipeline method to True. Each time the pipeline is created, dlt adds datetime-based suffix to the dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "95fbbd7b-f688-416b-9efc-0f5cf12b224f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:10:47.221276167Z",
     "start_time": "2023-09-04T09:10:46.744997133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline quick_start completed in 0.46 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata_20230904091046\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/quick_start.duckdb location to store data\n",
      "Load package 1693818646.790694 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "data = [\n",
    "\t{'id': 1, 'name': 'Alice'},\n",
    "\t{'id': 2, 'name': 'Bob'}\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='quick_start',\n",
    "\tdestination='duckdb',\n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=True, \n",
    ")\n",
    "load_info = pipeline.run(data, table_name=\"users\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24e9e0-8903-40e0-9b45-43ac5333e7c4",
   "metadata": {},
   "source": [
    "### Now explore your data! \n",
    "\n",
    "To see the schema of your created database, run Streamlit command:\n",
    "\n",
    "```python\n",
    " dlt pipeline <pipeline_name> show\n",
    "```\n",
    "[This command](https://dlthub.com/docs/reference/command-line-interface#show-tables-and-data-in-the-destination) generates and launches a simple Streamlit app that you can use to inspect the schemas and data in the destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706abe8-e820-4bf5-b9dc-20c4562f782e",
   "metadata": {},
   "source": [
    "To use `streamlit`, install it first.\n",
    "\n",
    "For example above pipeline name is “quick_start”, so run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "92682ee3-6cc9-411f-b926-abb362995bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T17:58:19.054419846Z",
     "start_time": "2023-09-02T17:58:17.780008365Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q streamlit pandas==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f9627343-508c-4f82-90bb-077f7dca392b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:13:39.254140397Z",
     "start_time": "2023-09-04T09:11:39.863163280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pipeline \u001B[1mquick_start\u001B[0m in \u001B[1m/home/alenaastrakhantseva/.dlt/pipelines\u001B[0m\r\n",
      "\r\n",
      "  You can now view your Streamlit app in your browser.\r\n",
      "\r\n",
      "  Local URL: http://localhost:8501\r\n",
      "  Network URL: http://172.16.0.2:8501\r\n",
      "\r\n",
      "^C\r\n",
      "  Stopping...\r\n"
     ]
    }
   ],
   "source": [
    "!dlt pipeline quick_start show"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd91fe343542c621"
  },
  {
   "cell_type": "markdown",
   "id": "c4a81884-9abe-4694-9c65-61e03a748cdc",
   "metadata": {},
   "source": [
    "## Load data from variety of sources\n",
    "\n",
    "Use dlt to load practically any data you deal with in your Python script into a dataset. \n",
    "\n",
    "The library will create/update tables, infer data types and deal with nested data automatically:\n",
    "- list of dicts\n",
    "- json\n",
    "- csv\n",
    "- API\n",
    "- database\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65b183-14bd-40af-a105-ca75c02d31c9",
   "metadata": {},
   "source": [
    "### from JSON\n",
    "\n",
    "When creating a schema during normalization, dlt recursively unpacks this nested structure into relational tables, creating and linking [children and parent tables](https://dlthub.com/docs/dlt-ecosystem/visualizations/understanding-the-tables#child-and-parent-tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c03def52-2831-4208-a0f2-340c010afa31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:14:43.865760881Z",
     "start_time": "2023-09-04T09:14:43.791750796Z"
    }
   },
   "outputs": [],
   "source": [
    "# create test json file\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"test.json\", 'w') as file:\n",
    "    data = {\n",
    "        'id': 1, \n",
    "        'name': 'Alice', \n",
    "        'job': {\n",
    "            \"company\": \"ScaleVector\",\n",
    "            \"title\": \"Data Scientist\",\n",
    "        },\n",
    "        'children': [\n",
    "            {\n",
    "                'id': 1, \n",
    "                'name': 'Eve'\n",
    "            },\n",
    "            {\n",
    "                'id': 2, \n",
    "                'name': 'Wendy'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    json.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14eba4a6-806f-4e69-966b-6804196bc5fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-09-04T09:14:46.335517704Z",
     "start_time": "2023-09-04T09:14:45.714030334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline from_json completed in 0.56 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata_20230904091445\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/from_json.duckdb location to store data\n",
      "Load package 1693818885.744856 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# load test json to duckdb database\n",
    "\n",
    "import json\n",
    "import dlt\n",
    "\n",
    "\n",
    "with open(\"test.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='from_json',\n",
    "\tdestination='duckdb', \n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=True,\n",
    ")\n",
    "# dlt works with lists of dicts, so wrap data to the list\n",
    "load_info = pipeline.run([data], table_name=\"json_data\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5ba66dc7-1607-4eaf-91f3-3a7faaf4e845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:15:46.956241708Z",
     "start_time": "2023-09-04T09:15:46.877783301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "┌───────────┬──────────────────────┬─────────────────────┬──────────────────────┬──────────────────────────┬───────────┐\n│ database  │        schema        │        name         │     column_names     │       column_types       │ temporary │\n│  varchar  │       varchar        │       varchar       │      varchar[]       │        varchar[]         │  boolean  │\n├───────────┼──────────────────────┼─────────────────────┼──────────────────────┼──────────────────────────┼───────────┤\n│ from_json │ mydata_20230904091…  │ _dlt_loads          │ [load_id, schema_n…  │ [VARCHAR, VARCHAR, BIG…  │ false     │\n│ from_json │ mydata_20230904091…  │ _dlt_pipeline_state │ [version, engine_v…  │ [BIGINT, BIGINT, VARCH…  │ false     │\n│ from_json │ mydata_20230904091…  │ _dlt_version        │ [version, engine_v…  │ [BIGINT, BIGINT, TIMES…  │ false     │\n│ from_json │ mydata_20230904091…  │ json_data           │ [id, name, job__co…  │ [BIGINT, VARCHAR, VARC…  │ false     │\n│ from_json │ mydata_20230904091…  │ json_data__children │ [id, name, _dlt_pa…  │ [BIGINT, VARCHAR, VARC…  │ false     │\n└───────────┴──────────────────────┴─────────────────────┴──────────────────────┴──────────────────────────┴───────────┘"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   id   name job__company      job__title       _dlt_load_id         _dlt_id\n0   1  Alice  ScaleVector  Data Scientist  1693818885.744856  +j3y0Oxq0pFlWA",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>job__company</th>\n      <th>job__title</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>ScaleVector</td>\n      <td>Data Scientist</td>\n      <td>1693818885.744856</td>\n      <td>+j3y0Oxq0pFlWA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "display(conn.sql(\"DESCRIBE\"))\n",
    "data_table = conn.sql(\"SELECT * FROM json_data\").df()\n",
    "data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e485b-9230-421e-8715-04500bbfce35",
   "metadata": {},
   "source": [
    "### from API\n",
    "\n",
    "Below we load 100 most recent issues from our [own dlt repository](https://github.com/dlt-hub/dlt) into \"issues\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e94608d3-ecab-462e-970a-5848de352833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:18:01.252793256Z",
     "start_time": "2023-09-04T09:17:59.638279822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline from_api completed in 0.85 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata_20230904091800\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/from_api.duckdb location to store data\n",
      "Load package 1693819080.431144 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "\n",
    "\n",
    "# url to request dlt-hub/dlt issues\n",
    "url = \"https://api.github.com/repos/dlt-hub/dlt/issues\"\n",
    "# make the request and check if succeeded\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='from_api',\n",
    "\tdestination='duckdb', \n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=True,\n",
    ")\n",
    "load_info = pipeline.run(response.json(), table_name=\"issues\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8acf3b3c-8657-4e0b-a63e-f21d86205389",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-04T09:18:04.041808808Z",
     "start_time": "2023-09-04T09:18:03.950112708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "┌──────────┬──────────────────────┬─────────────────────┬──────────────────────┬───────────────────────────┬───────────┐\n│ database │        schema        │        name         │     column_names     │       column_types        │ temporary │\n│ varchar  │       varchar        │       varchar       │      varchar[]       │         varchar[]         │  boolean  │\n├──────────┼──────────────────────┼─────────────────────┼──────────────────────┼───────────────────────────┼───────────┤\n│ from_api │ mydata_20230904091…  │ _dlt_loads          │ [load_id, schema_n…  │ [VARCHAR, VARCHAR, BIGI…  │ false     │\n│ from_api │ mydata_20230904091…  │ _dlt_pipeline_state │ [version, engine_v…  │ [BIGINT, BIGINT, VARCHA…  │ false     │\n│ from_api │ mydata_20230904091…  │ _dlt_version        │ [version, engine_v…  │ [BIGINT, BIGINT, TIMEST…  │ false     │\n│ from_api │ mydata_20230904091…  │ issues              │ [url, repository_u…  │ [VARCHAR, VARCHAR, VARC…  │ false     │\n│ from_api │ mydata_20230904091…  │ issues__assignees   │ [login, id, node_i…  │ [VARCHAR, BIGINT, VARCH…  │ false     │\n│ from_api │ mydata_20230904091…  │ issues__labels      │ [id, node_id, url,…  │ [BIGINT, VARCHAR, VARCH…  │ false     │\n└──────────┴──────────────────────┴─────────────────────┴──────────────────────┴───────────────────────────┴───────────┘"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                                 url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                             repository_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt   \n1  https://api.github.com/repos/dlt-hub/dlt   \n2  https://api.github.com/repos/dlt-hub/dlt   \n3  https://api.github.com/repos/dlt-hub/dlt   \n4  https://api.github.com/repos/dlt-hub/dlt   \n\n                                          labels_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                        comments_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                          events_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                    html_url          id              node_id  \\\n0    https://github.com/dlt-hub/dlt/pull/607  1879448366  PR_kwDOGvRYu85ZcM8t   \n1    https://github.com/dlt-hub/dlt/pull/606  1878822576  PR_kwDOGvRYu85ZaS70   \n2  https://github.com/dlt-hub/dlt/issues/605  1877653146   I_kwDOGvRYu85v6raa   \n3    https://github.com/dlt-hub/dlt/pull/603  1876027382  PR_kwDOGvRYu85ZQ-0y   \n4    https://github.com/dlt-hub/dlt/pull/601  1873728536  PR_kwDOGvRYu85ZJKdR   \n\n   number                                              title  ...  \\\n0     607                       Added MongoDB documentation.  ...   \n1     606                     Add support for TIME data type  ...   \n2     605                                  support TIME type  ...   \n3     603  Add module_config customization in the Weaviat...  ...   \n4     601                          Fixes docs on apply hints  ...   \n\n                             assignee__following_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/followi...   \n3                                                NaN   \n4                                                NaN   \n\n                                 assignee__gists_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/gists{/...   \n3                                                NaN   \n4                                                NaN   \n\n                               assignee__starred_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/starred...   \n3                                                NaN   \n4                                                NaN   \n\n                         assignee__subscriptions_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/subscri...   \n3                                                NaN   \n4                                                NaN   \n\n                   assignee__organizations_url  \\\n0                                          NaN   \n1                                          NaN   \n2  https://api.github.com/users/steinitzu/orgs   \n3                                          NaN   \n4                                          NaN   \n\n                            assignee__repos_url  \\\n0                                           NaN   \n1                                           NaN   \n2  https://api.github.com/users/steinitzu/repos   \n3                                           NaN   \n4                                           NaN   \n\n                                assignee__events_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/events{...   \n3                                                NaN   \n4                                                NaN   \n\n                       assignee__received_events_url assignee__type  \\\n0                                                NaN            NaN   \n1                                                NaN            NaN   \n2  https://api.github.com/users/steinitzu/receive...           User   \n3                                                NaN            NaN   \n4                                                NaN            NaN   \n\n  assignee__site_admin  \n0                  NaN  \n1                  NaN  \n2                False  \n3                  NaN  \n4                  NaN  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>repository_url</th>\n      <th>labels_url</th>\n      <th>comments_url</th>\n      <th>events_url</th>\n      <th>html_url</th>\n      <th>id</th>\n      <th>node_id</th>\n      <th>number</th>\n      <th>title</th>\n      <th>...</th>\n      <th>assignee__following_url</th>\n      <th>assignee__gists_url</th>\n      <th>assignee__starred_url</th>\n      <th>assignee__subscriptions_url</th>\n      <th>assignee__organizations_url</th>\n      <th>assignee__repos_url</th>\n      <th>assignee__events_url</th>\n      <th>assignee__received_events_url</th>\n      <th>assignee__type</th>\n      <th>assignee__site_admin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/607</td>\n      <td>1879448366</td>\n      <td>PR_kwDOGvRYu85ZcM8t</td>\n      <td>607</td>\n      <td>Added MongoDB documentation.</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/606</td>\n      <td>1878822576</td>\n      <td>PR_kwDOGvRYu85ZaS70</td>\n      <td>606</td>\n      <td>Add support for TIME data type</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/issues/605</td>\n      <td>1877653146</td>\n      <td>I_kwDOGvRYu85v6raa</td>\n      <td>605</td>\n      <td>support TIME type</td>\n      <td>...</td>\n      <td>https://api.github.com/users/steinitzu/followi...</td>\n      <td>https://api.github.com/users/steinitzu/gists{/...</td>\n      <td>https://api.github.com/users/steinitzu/starred...</td>\n      <td>https://api.github.com/users/steinitzu/subscri...</td>\n      <td>https://api.github.com/users/steinitzu/orgs</td>\n      <td>https://api.github.com/users/steinitzu/repos</td>\n      <td>https://api.github.com/users/steinitzu/events{...</td>\n      <td>https://api.github.com/users/steinitzu/receive...</td>\n      <td>User</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/603</td>\n      <td>1876027382</td>\n      <td>PR_kwDOGvRYu85ZQ-0y</td>\n      <td>603</td>\n      <td>Add module_config customization in the Weaviat...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/601</td>\n      <td>1873728536</td>\n      <td>PR_kwDOGvRYu85ZJKdR</td>\n      <td>601</td>\n      <td>Fixes docs on apply hints</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "display(conn.sql(\"DESCRIBE\"))\n",
    "data_table = conn.sql(\"SELECT * FROM issues\").df()\n",
    "data_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db4731-9484-4863-908e-7891c8c24bf9",
   "metadata": {},
   "source": [
    "## Append or replace your data\n",
    "\n",
    "Run this examples twice and you notice that each time a copy of the data is added to your tables.\n",
    "We call this load mode `append`. It is very useful when i.e. you have a new folder created daily with `json` file logs, and you want to ingest them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b3807b69-bf33-4881-b1f3-d8c744e43f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:19:04.132440944Z",
     "start_time": "2023-09-04T09:19:03.852544871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline append completed in 0.26 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/append.duckdb location to store data\n",
      "Load package 1693819143.898282 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "\n",
    "data = [\n",
    "\t{'id': 1, 'name': 'Alice'},\n",
    "\t{'id': 2, 'name': 'Bob'}\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='append',\n",
    "\tdestination='duckdb',\n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=False, \n",
    ")\n",
    "load_info = pipeline.run(data, table_name=\"users\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a59eebaf-b418-473f-82d5-09fe7fca67ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:19:04.893998643Z",
     "start_time": "2023-09-04T09:19:04.865751402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id   name       _dlt_load_id         _dlt_id\n0   1  Alice  1693819136.763849  6WSNEZYqGbBWeg\n1   2    Bob  1693819136.763849  QcnOcIZKxZZ/8w\n2   1  Alice  1693819143.898282  Cv/IeEVAfNCL+Q\n3   2    Bob  1693819143.898282  T8B6UpmcodfFyg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>1693819136.763849</td>\n      <td>6WSNEZYqGbBWeg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bob</td>\n      <td>1693819136.763849</td>\n      <td>QcnOcIZKxZZ/8w</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>1693819143.898282</td>\n      <td>Cv/IeEVAfNCL+Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Bob</td>\n      <td>1693819143.898282</td>\n      <td>T8B6UpmcodfFyg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "data_table = conn.sql(\"SELECT * FROM users\").df()\n",
    "data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd1ed0-3fc8-4129-89a0-de9b62ba01fe",
   "metadata": {},
   "source": [
    "Perhaps this is not what you want to do in the example above.\n",
    "For example, if the CSV file is updated, how we can refresh it in the database?\n",
    "One method is to tell `dlt` to replace the data in existing tables by using `write_disposition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "042bc584-b2da-474c-b72f-be7e822aa1ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:19:45.541779640Z",
     "start_time": "2023-09-04T09:19:45.206176576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline replace completed in 0.32 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/replace.duckdb location to store data\n",
      "Load package 1693819185.262428 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "\n",
    "data = [\n",
    "\t{'id': 1, 'name': 'Alice'},\n",
    "\t{'id': 2, 'name': 'Bob'}\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='replace',\n",
    "\tdestination='duckdb',\n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=False, \n",
    ")\n",
    "load_info = pipeline.run(data, table_name=\"users\", write_disposition=\"replace\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "59d16b9c-a5e9-40d6-87f3-d744de50791e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:19:46.367758599Z",
     "start_time": "2023-09-04T09:19:46.343441823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id   name       _dlt_load_id         _dlt_id\n0   1  Alice  1693819185.262428  jFrY0LpeuVPivg\n1   2    Bob  1693819185.262428  Xrlm9Zc3EebJ+A",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>1693819185.262428</td>\n      <td>jFrY0LpeuVPivg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bob</td>\n      <td>1693819185.262428</td>\n      <td>Xrlm9Zc3EebJ+A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "data_table = conn.sql(\"SELECT * FROM users\").df()\n",
    "data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b26d1-6b37-42dd-90ac-a1cd64106254",
   "metadata": {},
   "source": [
    "## Declare loading behavior\n",
    "\n",
    "You can finetune the loading process by decorating Python functions with `@dlt.resource`.\n",
    "\n",
    "### Load only new data (incremental loading)\n",
    "\n",
    "We can supercharge the example above and get only users that were created since last load.\n",
    "Instead of using `replace` write_disposition and downloading all users each time the pipeline is run, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "27e3232f-c120-4a68-81e4-567f2ec823fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:22:02.472937821Z",
     "start_time": "2023-09-04T09:22:02.164647188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline incremental completed in 0.29 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/incremental.duckdb location to store data\n",
      "Load package 1693819322.241362 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "\n",
    "data = [\n",
    "\t{'id': 1, 'name': 'Alice', 'created_at': \"2023-09-01\"},\n",
    "\t{'id': 2, 'name': 'Bob', 'created_at': \"2023-09-02\"},\n",
    "    {'id': 3, 'name': 'Chad', 'created_at': \"2023-09-03\"},\n",
    "    {'id': 4, 'name': 'Carol', 'created_at': \"2023-09-04\"}\n",
    "]\n",
    "\n",
    "@dlt.resource\n",
    "def users(\n",
    "    created_at=dlt.sources.incremental(\"created_at\", initial_value=\"2023-08-01\")\n",
    "):\n",
    "    yield from data\n",
    "    \n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='incremental',\n",
    "\tdestination='duckdb',\n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=False, \n",
    ")\n",
    "load_info = pipeline.run(users)\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262c3ea-e867-4928-9ced-6c83b2a83b72",
   "metadata": {},
   "source": [
    "We use the `@dlt.resource` decorator to declare table name to which data will be loaded and write disposition, which is `append` by default.\n",
    "\n",
    "We also use `dlt.sources.incremental` to track `created_at` field present in each user to filter only the newly created ones.\n",
    "\n",
    "Now run the script. It loads all the users from our test data to `duckdb`. Run it again, and you can see that no users got added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5a46cb2a-0343-4055-bbd4-a1a820633b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:22:04.129407948Z",
     "start_time": "2023-09-04T09:22:04.090087062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id   name  created_at       _dlt_load_id         _dlt_id\n0   1  Alice  2023-09-01   1693819298.15018  vB8l/GcWY6n8lw\n1   2    Bob  2023-09-02   1693819298.15018  z6ftrCSl7BHg4A\n2   3   Chad  2023-09-03   1693819298.15018  ODUplz+EUMJlRg\n3   4  Carol  2023-09-04  1693819322.241362  s7ybTxVmDCLbCQ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>created_at</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>2023-09-01</td>\n      <td>1693819298.15018</td>\n      <td>vB8l/GcWY6n8lw</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bob</td>\n      <td>2023-09-02</td>\n      <td>1693819298.15018</td>\n      <td>z6ftrCSl7BHg4A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Chad</td>\n      <td>2023-09-03</td>\n      <td>1693819298.15018</td>\n      <td>ODUplz+EUMJlRg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Carol</td>\n      <td>2023-09-04</td>\n      <td>1693819322.241362</td>\n      <td>s7ybTxVmDCLbCQ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "data_table = conn.sql(\"SELECT * FROM users\").df()\n",
    "data_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b729bbf5-237e-4de4-b765-16af9bbac335",
   "metadata": {},
   "source": [
    "## Update and deduplicate your data\n",
    "\n",
    "The script above finds new users and adds them to the database.\n",
    "It will ignore any updates to user information.\n",
    "Get always fresh content of all the users: combine an incremental load with `merge` write disposition,\n",
    "like in the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline merge completed in 0.07 seconds\n",
      "0 load package(s) were loaded to destination duckdb and into dataset None\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/merge.duckdb location to store data\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "\n",
    "data = [\n",
    "\t{'id': 1, 'name': 'Alice', 'created_at': \"2023-09-01\", 'updated_at': \"2023-09-01\"},\n",
    "\t{'id': 2, 'name': 'Boba', 'created_at': \"2023-09-02\", 'updated_at': \"2023-09-05\"},\n",
    "    {'id': 3, 'name': 'Chad', 'created_at': \"2023-09-03\", 'updated_at': \"2023-09-03\"},\n",
    "    {'id': 4, 'name': 'Carol', 'created_at': \"2023-09-04\", 'updated_at': \"2023-09-04\"}\n",
    "]\n",
    "\n",
    "@dlt.resource(\n",
    "    write_disposition=\"merge\",\n",
    "    primary_key=\"id\",\n",
    ")\n",
    "def users(\n",
    "    updated_at=dlt.sources.incremental(\"updated_at\", initial_value=\"2023-08-01\")\n",
    "):\n",
    "    yield from data\n",
    "    \n",
    "pipeline = dlt.pipeline(\n",
    "\tpipeline_name='merge',\n",
    "\tdestination='duckdb',\n",
    "\tdataset_name='mydata',\n",
    "    full_refresh=False, \n",
    ")\n",
    "load_info = pipeline.run(users)\n",
    "print(load_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T09:26:01.833981447Z",
     "start_time": "2023-09-04T09:26:01.745826974Z"
    }
   },
   "id": "8d60eafe894de988"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above we add `primary_key` hint that tells `dlt` how to identify the users in the database to find duplicates which content it will merge.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f203c3dfb6e084cd"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "   id   name  created_at  updated_at       _dlt_load_id         _dlt_id\n0   2   Boba  2023-09-02  2023-09-05  1693819361.004953  XPkSUWS/XYOe/g\n1   1  Alice  2023-09-01  2023-09-01  1693819361.004953  6HYWF4lUAUoTnA\n2   4  Carol  2023-09-04  2023-09-04  1693819361.004953  Ue2lSCGe7wgoNg\n3   3   Chad  2023-09-03  2023-09-03  1693819361.004953  SzObGfgXId/PHw",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>created_at</th>\n      <th>updated_at</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Boba</td>\n      <td>2023-09-02</td>\n      <td>2023-09-05</td>\n      <td>1693819361.004953</td>\n      <td>XPkSUWS/XYOe/g</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Alice</td>\n      <td>2023-09-01</td>\n      <td>2023-09-01</td>\n      <td>1693819361.004953</td>\n      <td>6HYWF4lUAUoTnA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Carol</td>\n      <td>2023-09-04</td>\n      <td>2023-09-04</td>\n      <td>1693819361.004953</td>\n      <td>Ue2lSCGe7wgoNg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Chad</td>\n      <td>2023-09-03</td>\n      <td>2023-09-03</td>\n      <td>1693819361.004953</td>\n      <td>SzObGfgXId/PHw</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "data_table = conn.sql(\"SELECT * FROM users\").df()\n",
    "data_table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T09:26:03.529032144Z",
     "start_time": "2023-09-04T09:26:03.452750779Z"
    }
   },
   "id": "4622c01a6fdc9196"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real life example\n",
    "\n",
    "We can improve the GitHub API example above and get only issues that were created since last load."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92af94689a376313"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "69ab3088-9cf1-4644-af47-e082e38f6756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:28:05.593605528Z",
     "start_time": "2023-09-04T09:28:02.249099614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline github_issues_merge completed in 3.29 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/github_issues_merge.duckdb location to store data\n",
      "Load package 1693819683.2984 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "\n",
    "\n",
    "@dlt.resource(\n",
    "    table_name=\"issues\",\n",
    "    write_disposition=\"merge\",\n",
    "    primary_key=\"id\",\n",
    ")\n",
    "def get_issues(\n",
    "    updated_at = dlt.sources.incremental(\"updated_at\", initial_value=\"1970-01-01T00:00:00Z\")\n",
    "):\n",
    "    # url to request dlt-hub issues\n",
    "    url = f\"https://api.github.com/repos/dlt-hub/dlt/issues?since={updated_at.last_value}\"\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        page_items = response.json()\n",
    "\n",
    "        if len(page_items) == 0:\n",
    "            break\n",
    "        yield page_items\n",
    "\n",
    "        if \"next\" not in response.links:\n",
    "            break\n",
    "        url = response.links[\"next\"][\"url\"]\n",
    "\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='github_issues_merge',\n",
    "    destination='duckdb',\n",
    "    dataset_name='mydata',\n",
    "    full_refresh=False,\n",
    ")\n",
    "# dlt works with lists of dicts, so wrap data to the list\n",
    "load_info = pipeline.run(get_issues)\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32471e-31d9-4571-9c89-cbf76df9bfba",
   "metadata": {},
   "source": [
    "\n",
    "Note that we now track the `updated_at` field - so we filter in all issues **updated** since the last pipeline run (which also includes newly created ones).\n",
    "\n",
    "Also pay attention how we use **since** [GitHub API](https://docs.github.com/en/rest/issues/issues?apiVersion=2022-11-28#list-repository-issues)\n",
    "and `updated_at.last_value` to tell GitHub which issues we are interested in. `updated_at.last_value` holds the last `updated_at` value from the previous run.\n",
    "\n",
    "Now you can run this script on a daily schedule, and each day you'll load only issues created after the time of the previous pipeline run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f0d5253-d549-43a9-9104-cca803770bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:28:09.446527782Z",
     "start_time": "2023-09-04T09:28:09.371351130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                                url  \\\n0  1879448366  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  1878822576  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  1877653146  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  1876027382  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  1873728536  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                             repository_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt   \n1  https://api.github.com/repos/dlt-hub/dlt   \n2  https://api.github.com/repos/dlt-hub/dlt   \n3  https://api.github.com/repos/dlt-hub/dlt   \n4  https://api.github.com/repos/dlt-hub/dlt   \n\n                                          labels_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                        comments_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                          events_url  \\\n0  https://api.github.com/repos/dlt-hub/dlt/issue...   \n1  https://api.github.com/repos/dlt-hub/dlt/issue...   \n2  https://api.github.com/repos/dlt-hub/dlt/issue...   \n3  https://api.github.com/repos/dlt-hub/dlt/issue...   \n4  https://api.github.com/repos/dlt-hub/dlt/issue...   \n\n                                    html_url              node_id  number  \\\n0    https://github.com/dlt-hub/dlt/pull/607  PR_kwDOGvRYu85ZcM8t     607   \n1    https://github.com/dlt-hub/dlt/pull/606  PR_kwDOGvRYu85ZaS70     606   \n2  https://github.com/dlt-hub/dlt/issues/605   I_kwDOGvRYu85v6raa     605   \n3    https://github.com/dlt-hub/dlt/pull/603  PR_kwDOGvRYu85ZQ-0y     603   \n4    https://github.com/dlt-hub/dlt/pull/601  PR_kwDOGvRYu85ZJKdR     601   \n\n                                               title  ...  \\\n0                       Added MongoDB documentation.  ...   \n1                     Add support for TIME data type  ...   \n2                                  support TIME type  ...   \n3  Add module_config customization in the Weaviat...  ...   \n4                          Fixes docs on apply hints  ...   \n\n                             assignee__following_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/followi...   \n3                                                NaN   \n4                                                NaN   \n\n                                 assignee__gists_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/gists{/...   \n3                                                NaN   \n4                                                NaN   \n\n                               assignee__starred_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/starred...   \n3                                                NaN   \n4                                                NaN   \n\n                         assignee__subscriptions_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/subscri...   \n3                                                NaN   \n4                                                NaN   \n\n                   assignee__organizations_url  \\\n0                                          NaN   \n1                                          NaN   \n2  https://api.github.com/users/steinitzu/orgs   \n3                                          NaN   \n4                                          NaN   \n\n                            assignee__repos_url  \\\n0                                           NaN   \n1                                           NaN   \n2  https://api.github.com/users/steinitzu/repos   \n3                                           NaN   \n4                                           NaN   \n\n                                assignee__events_url  \\\n0                                                NaN   \n1                                                NaN   \n2  https://api.github.com/users/steinitzu/events{...   \n3                                                NaN   \n4                                                NaN   \n\n                       assignee__received_events_url assignee__type  \\\n0                                                NaN            NaN   \n1                                                NaN            NaN   \n2  https://api.github.com/users/steinitzu/receive...           User   \n3                                                NaN            NaN   \n4                                                NaN            NaN   \n\n  assignee__site_admin  \n0                  NaN  \n1                  NaN  \n2                False  \n3                  NaN  \n4                  NaN  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>repository_url</th>\n      <th>labels_url</th>\n      <th>comments_url</th>\n      <th>events_url</th>\n      <th>html_url</th>\n      <th>node_id</th>\n      <th>number</th>\n      <th>title</th>\n      <th>...</th>\n      <th>assignee__following_url</th>\n      <th>assignee__gists_url</th>\n      <th>assignee__starred_url</th>\n      <th>assignee__subscriptions_url</th>\n      <th>assignee__organizations_url</th>\n      <th>assignee__repos_url</th>\n      <th>assignee__events_url</th>\n      <th>assignee__received_events_url</th>\n      <th>assignee__type</th>\n      <th>assignee__site_admin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1879448366</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/607</td>\n      <td>PR_kwDOGvRYu85ZcM8t</td>\n      <td>607</td>\n      <td>Added MongoDB documentation.</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1878822576</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/606</td>\n      <td>PR_kwDOGvRYu85ZaS70</td>\n      <td>606</td>\n      <td>Add support for TIME data type</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1877653146</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/issues/605</td>\n      <td>I_kwDOGvRYu85v6raa</td>\n      <td>605</td>\n      <td>support TIME type</td>\n      <td>...</td>\n      <td>https://api.github.com/users/steinitzu/followi...</td>\n      <td>https://api.github.com/users/steinitzu/gists{/...</td>\n      <td>https://api.github.com/users/steinitzu/starred...</td>\n      <td>https://api.github.com/users/steinitzu/subscri...</td>\n      <td>https://api.github.com/users/steinitzu/orgs</td>\n      <td>https://api.github.com/users/steinitzu/repos</td>\n      <td>https://api.github.com/users/steinitzu/events{...</td>\n      <td>https://api.github.com/users/steinitzu/receive...</td>\n      <td>User</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1876027382</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/603</td>\n      <td>PR_kwDOGvRYu85ZQ-0y</td>\n      <td>603</td>\n      <td>Add module_config customization in the Weaviat...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1873728536</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://api.github.com/repos/dlt-hub/dlt/issue...</td>\n      <td>https://github.com/dlt-hub/dlt/pull/601</td>\n      <td>PR_kwDOGvRYu85ZJKdR</td>\n      <td>601</td>\n      <td>Fixes docs on apply hints</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "data_table = conn.sql(\"SELECT * FROM issues\").df()\n",
    "data_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561db25-5296-4d5b-8466-1b860f8ef867",
   "metadata": {},
   "source": [
    "### Use existed verified sources\n",
    "\n",
    "To use existed verified source, just run the `dlt init` [command](https://dlthub.com/docs/reference/command-line-interface#dlt-init).\n",
    "\n",
    "List all verified sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0a79fa0d-ade6-4073-beeb-779ddf13e34c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:29:10.334136234Z",
     "start_time": "2023-09-04T09:29:06.772469428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up for verified sources in \u001B[1mhttps://github.com/dlt-hub/verified-sources.git\u001B[0m...\r\n",
      "\u001B[1mairtable\u001B[0m: Source that loads tables form Airtable.\r\n",
      "\u001B[1msalesforce\u001B[0m: Source for Salesforce depending on the simple_salesforce python package.\r\n",
      "\u001B[1mnotion\u001B[0m: A source that extracts data from Notion API\r\n",
      "\u001B[1mjira\u001B[0m: This source uses Jira API and dlt to load data such as Issues, Users, Workflows and Projects to the database. \r\n",
      "\u001B[1mhubspot\u001B[0m: This is a module that provides a DLT source to retrieve data from multiple endpoints of the HubSpot API using a specified API key. The retrieved data is returned as a tuple of Dlt resources, one for each endpoint.\r\n",
      "\u001B[1mpipedrive\u001B[0m: Highly customizable source for Pipedrive, supports endpoint addition, selection and column rename\r\n",
      "\u001B[1mchess\u001B[0m: A source loading player profiles and games from chess.com api\r\n",
      "\u001B[1masana_dlt\u001B[0m: This source provides data extraction from the Asana platform via their API.\r\n",
      "\u001B[1mfacebook_ads\u001B[0m: Loads campaigns, ads sets, ads, leads and insight data from Facebook Marketing API\r\n",
      "\u001B[1mworkable\u001B[0m: This source uses Workable API and dlt to load data such as Candidates, Jobs, Events, etc. to the database.\r\n",
      "\u001B[1munstructured_data\u001B[0m: This source converts unstructured data from a specified data resource to structured data using provided queries.\r\n",
      "\u001B[1mmatomo\u001B[0m: Loads reports and raw visits data from Matomo\r\n",
      "\u001B[1mmux\u001B[0m: Loads Mux views data using https://docs.mux.com/api-reference\r\n",
      "\u001B[1mgoogle_analytics\u001B[0m: Defines all the sources and resources needed for Google Analytics V4\r\n",
      "\u001B[1mstrapi\u001B[0m: Basic strapi source\r\n",
      "\u001B[1mzendesk\u001B[0m: Defines all the sources and resources needed for ZendeskSupport, ZendeskChat and ZendeskTalk\r\n",
      "\u001B[1munstructured_weaviate\u001B[0m: This source converts unstructured data from a specified data resource to structured data using provided queries.\r\n",
      "\u001B[1mgithub\u001B[0m: Source that load github issues, pull requests and reactions for a specific repository via customizable graphql query. Loads events incrementally.\r\n",
      "\u001B[1msql_database\u001B[0m: Source that loads tables form any SQLAlchemy supported database, supports batching requests and incremental loads.\r\n",
      "\u001B[1mstripe_analytics\u001B[0m: This source uses Stripe API and dlt to load data such as Customer, Subscription, Event etc. to the database and to calculate the MRR and churn rate. \r\n",
      "\u001B[1mpokemon\u001B[0m: This source provides data extraction from an example source as a starting point for new pipelines.\r\n",
      "\u001B[1mmongodb\u001B[0m: Source that loads collections form any a mongo database, supports incremental loads.\r\n",
      "\u001B[1mgoogle_sheets\u001B[0m: Loads Google Sheets data from tabs, named and explicit ranges. Contains the main source functions.\r\n",
      "\u001B[1mshopify_dlt\u001B[0m: Fetches Shopify Orders and Products.\r\n"
     ]
    }
   ],
   "source": [
    "!dlt init --list-verified-sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d7616-f4ed-46a6-b53d-efe7d01726d8",
   "metadata": {},
   "source": [
    "This command shows all available verified sources and their short descriptions. For each source, checks if your local `dlt` version requires update and prints the relevant warning.\n",
    "\n",
    "Consider an example of a pipeline for Pokemon API.\n",
    "\n",
    "This command will initialize the pipeline example with Pokemon as the source and `duckdb` as the [destination](https://dlthub.com/docs/dlt-ecosystem/destinations):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ecabaf6a-307a-4c9c-ac65-75c177536672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-09-04T09:29:29.443647544Z",
     "start_time": "2023-09-04T09:29:26.409082099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up the init scripts in \u001B[1mhttps://github.com/dlt-hub/verified-sources.git\u001B[0m...\r\n",
      "No files to update, exiting\r\n"
     ]
    }
   ],
   "source": [
    "!dlt --non-interactive init pokemon duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "27ea9297-c1e4-4de0-a301-0639fa86358f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:30:42.803517788Z",
     "start_time": "2023-09-04T09:30:38.208807809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline pokemon completed in 1.46 seconds\r\n",
      "1 load package(s) were loaded to destination duckdb and into dataset pokemon_data\r\n",
      "The duckdb destination used duckdb:////home/alenaastrakhantseva/dlthub/spotlight_demo/pokemon.duckdb location to store data\r\n",
      "Load package 1693819840.581949 is LOADED and contains no failed jobs\r\n"
     ]
    }
   ],
   "source": [
    "!python pokemon_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "72ced5c7-c2b2-47de-bcf6-ca8e0900d9e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T09:30:43.071298211Z",
     "start_time": "2023-09-04T09:30:43.004537860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "┌──────────┬──────────────┬─────────────────────┬──────────────────────┬───────────────────────────────────┬───────────┐\n│ database │    schema    │        name         │     column_names     │           column_types            │ temporary │\n│ varchar  │   varchar    │       varchar       │      varchar[]       │             varchar[]             │  boolean  │\n├──────────┼──────────────┼─────────────────────┼──────────────────────┼───────────────────────────────────┼───────────┤\n│ pokemon  │ pokemon_data │ _dlt_loads          │ [load_id, schema_n…  │ [VARCHAR, VARCHAR, BIGINT, TIME…  │ false     │\n│ pokemon  │ pokemon_data │ _dlt_pipeline_state │ [version, engine_v…  │ [BIGINT, BIGINT, VARCHAR, VARCH…  │ false     │\n│ pokemon  │ pokemon_data │ _dlt_version        │ [version, engine_v…  │ [BIGINT, BIGINT, TIMESTAMP WITH…  │ false     │\n│ pokemon  │ pokemon_data │ berries             │ [name, url, _dlt_l…  │ [VARCHAR, VARCHAR, VARCHAR, VAR…  │ false     │\n│ pokemon  │ pokemon_data │ pokemon             │ [name, url, _dlt_l…  │ [VARCHAR, VARCHAR, VARCHAR, VAR…  │ false     │\n└──────────┴──────────────┴─────────────────────┴──────────────────────┴───────────────────────────────────┴───────────┘"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "          name                                    url       _dlt_load_id  \\\n0    bulbasaur   https://pokeapi.co/api/v2/pokemon/1/  1693819840.581949   \n1      ivysaur   https://pokeapi.co/api/v2/pokemon/2/  1693819840.581949   \n2     venusaur   https://pokeapi.co/api/v2/pokemon/3/  1693819840.581949   \n3   charmander   https://pokeapi.co/api/v2/pokemon/4/  1693819840.581949   \n4   charmeleon   https://pokeapi.co/api/v2/pokemon/5/  1693819840.581949   \n5    charizard   https://pokeapi.co/api/v2/pokemon/6/  1693819840.581949   \n6     squirtle   https://pokeapi.co/api/v2/pokemon/7/  1693819840.581949   \n7    wartortle   https://pokeapi.co/api/v2/pokemon/8/  1693819840.581949   \n8    blastoise   https://pokeapi.co/api/v2/pokemon/9/  1693819840.581949   \n9     caterpie  https://pokeapi.co/api/v2/pokemon/10/  1693819840.581949   \n10     metapod  https://pokeapi.co/api/v2/pokemon/11/  1693819840.581949   \n11  butterfree  https://pokeapi.co/api/v2/pokemon/12/  1693819840.581949   \n12      weedle  https://pokeapi.co/api/v2/pokemon/13/  1693819840.581949   \n13      kakuna  https://pokeapi.co/api/v2/pokemon/14/  1693819840.581949   \n14    beedrill  https://pokeapi.co/api/v2/pokemon/15/  1693819840.581949   \n15      pidgey  https://pokeapi.co/api/v2/pokemon/16/  1693819840.581949   \n16   pidgeotto  https://pokeapi.co/api/v2/pokemon/17/  1693819840.581949   \n17     pidgeot  https://pokeapi.co/api/v2/pokemon/18/  1693819840.581949   \n18     rattata  https://pokeapi.co/api/v2/pokemon/19/  1693819840.581949   \n19    raticate  https://pokeapi.co/api/v2/pokemon/20/  1693819840.581949   \n\n           _dlt_id  \n0   LE2RgzOt4YRRZA  \n1   5p0B1OMIsSHPbA  \n2   sUOy96OHI9ezXQ  \n3   EhXIRYatjZx66g  \n4   QhrBLgATqWWZ5w  \n5   qm6zHHCZv0s3nw  \n6   tjMaCTD3iXHlQg  \n7   n8opSKh8vrIrZQ  \n8   6NgYFW7S68zEbA  \n9   IwPQMfnqu/3zTQ  \n10  /ybEGGPVCJvT6Q  \n11  6toVlibkqwWtWA  \n12  ntHEmppRk3kkhQ  \n13  y3+wtpI15mL+Nw  \n14  NEp+XkQvs7XGZg  \n15  gPU85sjhca0bmA  \n16  3yOPsKURjKsSnQ  \n17  LR9GzFw9bOrNRA  \n18  Pvv6FmsBoVkKIw  \n19  N6/DzMAKyZTwyw  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>url</th>\n      <th>_dlt_load_id</th>\n      <th>_dlt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bulbasaur</td>\n      <td>https://pokeapi.co/api/v2/pokemon/1/</td>\n      <td>1693819840.581949</td>\n      <td>LE2RgzOt4YRRZA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ivysaur</td>\n      <td>https://pokeapi.co/api/v2/pokemon/2/</td>\n      <td>1693819840.581949</td>\n      <td>5p0B1OMIsSHPbA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>venusaur</td>\n      <td>https://pokeapi.co/api/v2/pokemon/3/</td>\n      <td>1693819840.581949</td>\n      <td>sUOy96OHI9ezXQ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>charmander</td>\n      <td>https://pokeapi.co/api/v2/pokemon/4/</td>\n      <td>1693819840.581949</td>\n      <td>EhXIRYatjZx66g</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>charmeleon</td>\n      <td>https://pokeapi.co/api/v2/pokemon/5/</td>\n      <td>1693819840.581949</td>\n      <td>QhrBLgATqWWZ5w</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>charizard</td>\n      <td>https://pokeapi.co/api/v2/pokemon/6/</td>\n      <td>1693819840.581949</td>\n      <td>qm6zHHCZv0s3nw</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>squirtle</td>\n      <td>https://pokeapi.co/api/v2/pokemon/7/</td>\n      <td>1693819840.581949</td>\n      <td>tjMaCTD3iXHlQg</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>wartortle</td>\n      <td>https://pokeapi.co/api/v2/pokemon/8/</td>\n      <td>1693819840.581949</td>\n      <td>n8opSKh8vrIrZQ</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>blastoise</td>\n      <td>https://pokeapi.co/api/v2/pokemon/9/</td>\n      <td>1693819840.581949</td>\n      <td>6NgYFW7S68zEbA</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>caterpie</td>\n      <td>https://pokeapi.co/api/v2/pokemon/10/</td>\n      <td>1693819840.581949</td>\n      <td>IwPQMfnqu/3zTQ</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>metapod</td>\n      <td>https://pokeapi.co/api/v2/pokemon/11/</td>\n      <td>1693819840.581949</td>\n      <td>/ybEGGPVCJvT6Q</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>butterfree</td>\n      <td>https://pokeapi.co/api/v2/pokemon/12/</td>\n      <td>1693819840.581949</td>\n      <td>6toVlibkqwWtWA</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>weedle</td>\n      <td>https://pokeapi.co/api/v2/pokemon/13/</td>\n      <td>1693819840.581949</td>\n      <td>ntHEmppRk3kkhQ</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>kakuna</td>\n      <td>https://pokeapi.co/api/v2/pokemon/14/</td>\n      <td>1693819840.581949</td>\n      <td>y3+wtpI15mL+Nw</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>beedrill</td>\n      <td>https://pokeapi.co/api/v2/pokemon/15/</td>\n      <td>1693819840.581949</td>\n      <td>NEp+XkQvs7XGZg</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pidgey</td>\n      <td>https://pokeapi.co/api/v2/pokemon/16/</td>\n      <td>1693819840.581949</td>\n      <td>gPU85sjhca0bmA</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>pidgeotto</td>\n      <td>https://pokeapi.co/api/v2/pokemon/17/</td>\n      <td>1693819840.581949</td>\n      <td>3yOPsKURjKsSnQ</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>pidgeot</td>\n      <td>https://pokeapi.co/api/v2/pokemon/18/</td>\n      <td>1693819840.581949</td>\n      <td>LR9GzFw9bOrNRA</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>rattata</td>\n      <td>https://pokeapi.co/api/v2/pokemon/19/</td>\n      <td>1693819840.581949</td>\n      <td>Pvv6FmsBoVkKIw</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>raticate</td>\n      <td>https://pokeapi.co/api/v2/pokemon/20/</td>\n      <td>1693819840.581949</td>\n      <td>N6/DzMAKyZTwyw</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"pokemon.duckdb\")\n",
    "conn.sql(f\"SET search_path = 'pokemon_data'\")\n",
    "display(conn.sql(\"DESCRIBE\"))\n",
    "data_table = conn.sql(\"SELECT * FROM pokemon\").df()\n",
    "data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T17:58:39.038837170Z",
     "start_time": "2023-09-02T17:58:39.036761770Z"
    }
   },
   "id": "9fc87f805b82a941"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "spotlight_demo",
   "language": "python",
   "display_name": "Python (spotlight_demo)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
